hparams:
  model_arch: vit_som
  total_epochs: 200
  batch_size: 256
  gamma: 0.0005

  som:
    map_size: [24, 24]
    Tmax: 24
    Tmin: 0.1
    distance_fcn: cosine
    use_reduced: False

  vit:
    patch_size: 2
    emb_dim: 16
    enc_depth: 4
    dec_depth: 2
    heads: 2
    mlp_ratio: 4
    qkv_bias: True
    qk_norm: False
    proj_drop: 0.0
    attn_drop: 0.0
    drop_path: 0.1
    global_pool: False

  optimizer:
    type: adamw
    lr: 0.0005
    min_lr: 0.00001
    beta_1: 0.9
    beta_2: 0.999
    scheduler: cosine_annealing
    warmup_epochs: 10
    weight_decay: 0.0
    layer_decay: 1.0
    smoothing: 0.0

data:
  dataset: usps
  num_classes: 0
  num_channels: 1
  input_size: 16
  num_workers: 16

  augment:
    horizontal_flip: 0.0
    randaug_n: 0
    resize_scale: [1.0, 1.0]
    resize_ratio: [1.0, 1.0]
    reprob: 0.0
    remode: 'pixel'
    recount: 0
    mixup_alpha: 0.0
    mixup_prob: 0
    mixup_mode: 'batch'
    autoaugment: False
